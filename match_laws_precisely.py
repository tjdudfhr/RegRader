#!/usr/bin/env python3
import json
import re
from difflib import SequenceMatcher
from datetime import datetime

def load_our_212_laws():
    """ìš°ë¦¬ê°€ ë¶„ë¥˜í•œ 212ê°œ ë²•ë ¹ ë¡œë“œ"""
    with open('docs/index.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data['items']

def load_crawled_2025_laws():
    """í¬ë¡¤ë§ëœ ì‹¤ì œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ë¡œë“œ"""
    with open('docs/crawled_2025_laws.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data['laws']

def normalize_law_title(title):
    """ë²•ë ¹ëª… ì •ê·œí™” (ë§¤ì¹­ì„ ìœ„í•œ ì „ì²˜ë¦¬)"""
    if not title:
        return ""
    
    # ê³µë°± ì œê±°
    normalized = re.sub(r'\s+', '', title)
    
    # íŠ¹ìˆ˜ë¬¸ìž ì •ë¦¬
    normalized = re.sub(r'[()ï¼ˆï¼‰\[\]ã€ã€‘]', '', normalized)
    
    # í•œìž ê´„í˜¸ ì œê±° (ì˜ˆ: æ³•å¾‹ -> ë²•ë¥ )
    normalized = re.sub(r'\([^)]*\)', '', normalized)
    
    # ì†Œë¬¸ìžë¡œ ë³€í™˜
    normalized = normalized.lower()
    
    return normalized

def similarity_score(str1, str2):
    """ë‘ ë¬¸ìžì—´ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""
    return SequenceMatcher(None, str1, str2).ratio()

def extract_base_law_name(title):
    """ê¸°ë³¸ ë²•ë ¹ëª… ì¶”ì¶œ (ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ë“± ì œê±°)"""
    # ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ë“± ì œê±°
    base = re.sub(r'(ì‹œí–‰ë ¹|ì‹œí–‰ê·œì¹™|ì‹œí–‰ì„¸ì¹™|ì‹œí–‰ê·œì •)$', '', title)
    base = re.sub(r'(ì˜ì‹œí–‰ì—ê´€í•œ|ì—ê´€í•œ|ê´€ë ¨).*', '', base)
    return base.strip()

def match_laws_precisely(our_laws, crawled_laws):
    """ì •í™•í•œ ë²•ë ¹ ë§¤ì¹­"""
    
    print("ðŸ” 212ê°œ ë²•ë ¹ê³¼ ì‹¤ì œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ì •í™•í•œ ë§¤ì¹­ ì‹œìž‘...")
    
    matched_laws = []
    unmatched_our_laws = []
    matching_stats = {
        "exact_matches": 0,
        "fuzzy_matches": 0,
        "base_name_matches": 0,
        "no_matches": 0
    }
    
    for our_law in our_laws:
        our_title = our_law.get('title', '')
        our_normalized = normalize_law_title(our_title)
        our_base_name = extract_base_law_name(our_title)
        
        best_match = None
        best_score = 0.0
        match_type = "no_match"
        
        for crawled_law in crawled_laws:
            crawled_title = crawled_law.get('title', '')
            crawled_normalized = normalize_law_title(crawled_title)
            
            # 1. ì •í™•í•œ ë§¤ì¹­ ì‹œë„
            if our_normalized == crawled_normalized:
                best_match = crawled_law
                best_score = 1.0
                match_type = "exact"
                break
            
            # 2. ê¸°ë³¸ ë²•ë ¹ëª… ë§¤ì¹­ ì‹œë„ (ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™ ë¬´ì‹œ)
            crawled_base = extract_base_law_name(crawled_title)
            our_base_normalized = normalize_law_title(our_base_name)
            crawled_base_normalized = normalize_law_title(crawled_base)
            
            if our_base_normalized == crawled_base_normalized and len(our_base_normalized) > 3:
                score = 0.9  # ê¸°ë³¸ëª… ë§¤ì¹­ì€ 0.9ì 
                if score > best_score:
                    best_match = crawled_law
                    best_score = score
                    match_type = "base_name"
            
            # 3. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (ìµœì†Œ 75% ì´ìƒ)
            similarity = similarity_score(our_normalized, crawled_normalized)
            if similarity >= 0.75 and similarity > best_score:
                best_match = crawled_law
                best_score = similarity
                match_type = "fuzzy"
        
        # ë§¤ì¹­ ê²°ê³¼ ì²˜ë¦¬
        if best_match and best_score >= 0.75:
            # ìš°ë¦¬ ë²•ë ¹ ì •ë³´ë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ê³ , ì‹¤ì œ ì‹œí–‰ì¼ìž ì—…ë°ì´íŠ¸
            matched_law = our_law.copy()
            matched_law['effectiveDate'] = best_match['effectiveDate']
            matched_law['actual_title'] = best_match['title']
            matched_law['match_score'] = best_score
            matched_law['match_type'] = match_type
            matched_law['government_lsId'] = best_match.get('lsId', '')
            matched_law['government_ministry'] = best_match.get('ministry', '')
            
            matched_laws.append(matched_law)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if match_type == "exact":
                matching_stats["exact_matches"] += 1
            elif match_type == "base_name":
                matching_stats["base_name_matches"] += 1
            else:
                matching_stats["fuzzy_matches"] += 1
            
            print(f"âœ… ë§¤ì¹­: {our_title[:30]}... -> {best_match['title'][:30]}... (ì ìˆ˜: {best_score:.3f}, íƒ€ìž…: {match_type})")
        
        else:
            unmatched_our_laws.append(our_law)
            matching_stats["no_matches"] += 1
            print(f"âŒ ë¯¸ë§¤ì¹­: {our_title}")
    
    return matched_laws, unmatched_our_laws, matching_stats

def categorize_matched_laws(matched_laws):
    """ë§¤ì¹­ëœ ë²•ë ¹ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    
    # ì§ë¬´ë³„ ë¶„ë¥˜
    by_category = {}
    for law in matched_laws:
        categories = law.get('categories', ['ê¸°íƒ€'])
        for category in categories:
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(law)
    
    # ë¶„ê¸°ë³„ ë¶„ë¥˜
    by_quarter = {"Q1": [], "Q2": [], "Q3": [], "Q4": []}
    for law in matched_laws:
        eff_date = law.get('effectiveDate', '')
        if len(eff_date) >= 7:
            month = int(eff_date[5:7])
            if 1 <= month <= 3:
                by_quarter["Q1"].append(law)
            elif 4 <= month <= 6:
                by_quarter["Q2"].append(law)
            elif 7 <= month <= 9:
                by_quarter["Q3"].append(law)
            elif 10 <= month <= 12:
                by_quarter["Q4"].append(law)
    
    # ì‹œí–‰ ìƒíƒœë³„ ë¶„ë¥˜ (í˜„ìž¬ ë‚ ì§œ ê¸°ì¤€)
    from datetime import date
    today = date.today()
    
    implemented = []  # ì´ë¯¸ ì‹œí–‰
    upcoming = []     # ì‹œí–‰ ì˜ˆì •
    
    for law in matched_laws:
        eff_date_str = law.get('effectiveDate', '')
        if eff_date_str:
            try:
                eff_date = datetime.strptime(eff_date_str, '%Y-%m-%d').date()
                if eff_date <= today:
                    implemented.append(law)
                else:
                    upcoming.append(law)
            except:
                pass
    
    return {
        'by_category': by_category,
        'by_quarter': by_quarter,
        'implemented': implemented,
        'upcoming': upcoming
    }

def save_matching_results(matched_laws, unmatched_laws, matching_stats, classifications):
    """ë§¤ì¹­ ê²°ê³¼ ì €ìž¥"""
    
    result = {
        "matched_at": datetime.now().isoformat(),
        "total_our_laws": len(matched_laws) + len(unmatched_laws),
        "matched_count": len(matched_laws),
        "unmatched_count": len(unmatched_laws),
        "matching_stats": matching_stats,
        "match_percentage": round((len(matched_laws) / (len(matched_laws) + len(unmatched_laws))) * 100, 2),
        
        # ë¶„ë¥˜ ê²°ê³¼
        "by_category_counts": {cat: len(laws) for cat, laws in classifications['by_category'].items()},
        "by_quarter_counts": {q: len(laws) for q, laws in classifications['by_quarter'].items()},
        "implemented_count": len(classifications['implemented']),
        "upcoming_count": len(classifications['upcoming']),
        
        # ì‹¤ì œ ë²•ë ¹ ë°ì´í„°
        "matched_laws": matched_laws,
        "unmatched_laws": unmatched_laws,
        "classifications": classifications
    }
    
    # ì €ìž¥
    with open('docs/precise_law_matching.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ðŸ“Š ì •í™•í•œ ë²•ë ¹ ë§¤ì¹­ ê²°ê³¼")
    print("="*60)
    print(f"ðŸŽ¯ ì „ì²´ ë²•ë ¹: {result['total_our_laws']}ê°œ")
    print(f"âœ… ë§¤ì¹­ ì„±ê³µ: {result['matched_count']}ê°œ ({result['match_percentage']}%)")
    print(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {result['unmatched_count']}ê°œ")
    print()
    print("ðŸ“ˆ ë§¤ì¹­ ë°©ì‹ë³„ í†µê³„:")
    for match_type, count in matching_stats.items():
        print(f"   {match_type}: {count}ê°œ")
    print()
    print("ðŸ“… ë¶„ê¸°ë³„ ë¶„í¬ (ë§¤ì¹­ëœ ë²•ë ¹):")
    for quarter, count in result['by_quarter_counts'].items():
        print(f"   {quarter}: {count}ê°œ")
    print()
    print("ðŸ‘¥ ì§ë¬´ë³„ ë¶„í¬ (ë§¤ì¹­ëœ ë²•ë ¹):")
    for category, count in sorted(result['by_category_counts'].items()):
        print(f"   {category}: {count}ê°œ")
    print()
    print(f"ðŸ“Š ì‹œí–‰ ìƒíƒœ:")
    print(f"   ì´ë¯¸ ì‹œí–‰: {result['implemented_count']}ê°œ")
    print(f"   ì‹œí–‰ ì˜ˆì •: {result['upcoming_count']}ê°œ")
    print()
    print(f"ðŸ’¾ ê²°ê³¼ ì €ìž¥: docs/precise_law_matching.json")
    
    return result

def main():
    print("ðŸš€ ì •í™•í•œ ë²•ë ¹ ë§¤ì¹­ í”„ë¡œì„¸ìŠ¤ ì‹œìž‘!")
    
    # 1. ë°ì´í„° ë¡œë“œ
    our_laws = load_our_212_laws()
    crawled_laws = load_crawled_2025_laws()
    
    print(f"ðŸ“‹ ìš°ë¦¬ ë²•ë ¹: {len(our_laws)}ê°œ")
    print(f"ðŸ›ï¸ í¬ë¡¤ë§ëœ 2025ë…„ ì‹œí–‰ ë²•ë ¹: {len(crawled_laws)}ê°œ")
    print()
    
    # 2. ì •í™•í•œ ë§¤ì¹­
    matched_laws, unmatched_laws, matching_stats = match_laws_precisely(our_laws, crawled_laws)
    
    # 3. ë¶„ë¥˜
    classifications = categorize_matched_laws(matched_laws)
    
    # 4. ê²°ê³¼ ì €ìž¥
    result = save_matching_results(matched_laws, unmatched_laws, matching_stats, classifications)
    
    return result

if __name__ == "__main__":
    main()