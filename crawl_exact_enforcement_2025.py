#!/usr/bin/env python3
import os, sys, json, time, random, re
import urllib.parse, urllib.request
from datetime import datetime
from html import unescape

# ê¸°ì¡´ ì‘ë™í•˜ë˜ ì„¤ì • ì‚¬ìš©
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) law-watch/3.3"
OPENAPI_BASE = "https://www.law.go.kr/DRF/lawSearch.do"
LAW_OC = "20241119YCRNECRQT4Q7SHAZE6P5AXRF"

def http_get(url, timeout=45, headers=None, retries=3, backoff=2.0):
    """HTTP GET ìš”ì²­"""
    last = None
    hdr = {"User-Agent": UA, "Accept": "*/*"}
    if headers: hdr.update(headers)
    
    for i in range(retries):
        try:
            req = urllib.request.Request(url, headers=hdr)
            with urllib.request.urlopen(req, timeout=timeout) as r:
                return r.read()
        except Exception as e:
            last = e
            sleep = (backoff ** i) + random.uniform(0, 0.6)
            print(f"[WARN] GET ì‹¤íŒ¨ ({i+1}/{retries}) {url} -> {e}; ì¬ì‹œë„ {sleep:.1f}ì´ˆ í›„", file=sys.stderr)
            time.sleep(sleep)
    
    print(f"[ERROR] GET ìµœì¢… ì‹¤íŒ¨: {url} -> {last}", file=sys.stderr)
    return None

def yyyymmdd_to_iso(s):
    """YYYYMMDD í˜•ì‹ì„ YYYY-MM-DDë¡œ ë³€í™˜"""
    if not s: return None
    s = str(s)
    m = re.search(r"(\d{4})(\d{2})(\d{2})", s)
    if not m: return None
    y, mm, dd = map(int, m.groups())
    return f"{y:04d}-{mm:02d}-{dd:02d}"

def extract_laws_from_json_precise(data):
    """JSON ë°ì´í„°ì—ì„œ ë²•ë ¹ ì •ë³´ ì •í™•í•˜ê²Œ ì¶”ì¶œ"""
    laws = []
    
    # LawSearch ì‘ë‹µ êµ¬ì¡° í™•ì¸
    if isinstance(data, dict):
        # ê°€ëŠ¥í•œ ë²•ë ¹ ëª©ë¡ ê²½ë¡œë“¤
        law_list = None
        
        # ë‹¤ì–‘í•œ ê²½ë¡œ ì‹œë„
        if 'LawSearch' in data:
            law_list = data['LawSearch']
        elif 'response' in data:
            law_list = data['response']
        elif 'result' in data:
            law_list = data['result']
        elif 'laws' in data:
            law_list = data['laws']
        elif isinstance(data, list):
            law_list = data
        
        if not law_list:
            print("âš ï¸ ë²•ë ¹ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return laws
        
        # ë²•ë ¹ ëª©ë¡ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° í•˜ìœ„ í•­ëª© ì°¾ê¸°
        if isinstance(law_list, dict):
            for key, value in law_list.items():
                if isinstance(value, list) and len(value) > 0:
                    law_list = value
                    break
        
        if not isinstance(law_list, list):
            print(f"âš ï¸ ë²•ë ¹ ëª©ë¡ì´ ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤: {type(law_list)}")
            return laws
        
        print(f"ğŸ“‹ {len(law_list)}ê°œ ë²•ë ¹ í•­ëª© ë°œê²¬")
        
        for item in law_list:
            if not isinstance(item, dict):
                continue
            
            # ì‹œí–‰ì¼ í™•ì¸ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª…)
            enforcement_date = None
            for date_field in ['ì‹œí–‰ì¼ì', 'ì‹œí–‰ì¼', 'efYd', 'enfcDate', 'effectiveDate']:
                if date_field in item and item[date_field]:
                    date_str = str(item[date_field])
                    # 2025ë…„ í¬í•¨ í™•ì¸
                    if '2025' in date_str:
                        enforcement_date = yyyymmdd_to_iso(date_str) or date_str
                        break
            
            # 2025ë…„ ì‹œí–‰ì´ ì•„ë‹ˆë©´ ì œì™¸
            if not enforcement_date or '2025' not in enforcement_date:
                continue
            
            # ë²•ë ¹ëª… ì¶”ì¶œ
            title = None
            for title_field in ['ë²•ë ¹ëª…', 'ë²•ë ¹ëª…ì¹­', 'lawNm', 'title']:
                if title_field in item and item[title_field]:
                    title = item[title_field].strip()
                    break
            
            if not title:
                continue
            
            # ì •ê·œí™”ëœ ë²•ë ¹ ì •ë³´
            law_info = {
                'title': title,
                'enforcement_date': enforcement_date,
                'lsId': item.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸') or item.get('lsId') or '',
                'promulgation_date': yyyymmdd_to_iso(item.get('ê³µí¬ì¼ì') or item.get('promDate') or ''),
                'ministry': item.get('ì†Œê´€ë¶€ì²˜') or item.get('minstNm') or '',
                'law_type': item.get('ë²•ì¢…êµ¬ë¶„') or item.get('lawType') or '',
                'raw_data': item
            }
            
            laws.append(law_info)
            
        print(f"âœ… {len(laws)}ê°œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ì¶”ì¶œ ì™„ë£Œ")
    
    return laws

def crawl_exact_2025_enforcement_laws():
    """ì •í™•í•œ ì‹œí–‰ì¼ ê¸°ì¤€ìœ¼ë¡œ 2025ë…„ ë²•ë ¹ í¬ë¡¤ë§"""
    
    print("ğŸ¯ ì‹œí–‰ì¼ ê¸°ì¤€ 2025ë…„ ë²•ë ¹ ì •í™•í•œ í¬ë¡¤ë§ ì‹œì‘!")
    print("=" * 60)
    
    # 2025ë…„ ì „ì²´ ê¸°ê°„
    start_date = "20250101"
    end_date = "20251231"
    
    all_laws = []
    
    # ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    for page in range(1, 25):  # ìµœëŒ€ 25í˜ì´ì§€ê¹Œì§€
        print(f"ğŸ“„ í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")
        
        params = {
            "OC": LAW_OC,
            "target": "eflaw",  # ì‹œí–‰ë²•ë ¹
            "type": "JSON",
            "display": "100",   # í˜ì´ì§€ë‹¹ 100ê°œ
            "page": str(page),
            "efYd": f"{start_date}~{end_date}",  # ì‹œí–‰ì¼ì ë²”ìœ„
            "sort": "efdes",    # ì‹œí–‰ì¼ì ë‚´ë¦¼ì°¨ìˆœ
        }
        
        url = OPENAPI_BASE + "?" + urllib.parse.urlencode(params, safe="~:")
        print(f"ğŸŒ ìš”ì²­ URL: {url[:100]}...")
        
        raw = http_get(url)
        if not raw:
            print(f"âŒ í˜ì´ì§€ {page} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            break
            
        # ë””ë²„ê·¸ìš© ì €ì¥
        os.makedirs("docs/_debug", exist_ok=True)
        with open(f"docs/_debug/exact_enforcement_p{page}.json", "wb") as f:
            f.write(raw)
        
        try:
            data = json.loads(raw.decode("utf-8", "ignore"))
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # ì›ì‹œ ì‘ë‹µ í™•ì¸
            raw_text = raw.decode("utf-8", "ignore")[:500]
            print(f"ğŸ“„ ì›ì‹œ ì‘ë‹µ ìƒ˜í”Œ: {raw_text}")
            break
        
        # ë²•ë ¹ ë°ì´í„° ì •í™•í•˜ê²Œ ì¶”ì¶œ
        page_laws = extract_laws_from_json_precise(data)
        
        if not page_laws:
            print(f"ğŸ“„ í˜ì´ì§€ {page}ì—ì„œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ì—†ìŒ, í¬ë¡¤ë§ ì¢…ë£Œ")
            break
            
        all_laws.extend(page_laws)
        print(f"âœ… í˜ì´ì§€ {page}: {len(page_laws)}ê°œ ë²•ë ¹ ìˆ˜ì§‘ (ì´ {len(all_laws)}ê°œ)")
        
        # API ë¶€í•˜ ë°©ì§€
        if page % 5 == 0:
            print("â¸ï¸ API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°...")
            time.sleep(2)
        else:
            time.sleep(0.8)
    
    if not all_laws:
        print("âŒ ì‹œí–‰ì¼ ê¸°ì¤€ 2025ë…„ ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¤‘ë³µ ì œê±° (lsId ê¸°ì¤€)
    unique_laws = {}
    for law in all_laws:
        key = law['lsId'] or law['title']  # lsIdê°€ ì—†ìœ¼ë©´ ì œëª©ìœ¼ë¡œ
        if key not in unique_laws:
            unique_laws[key] = law
    
    unique_laws_list = list(unique_laws.values())
    
    # ê²°ê³¼ ì •ë¦¬
    result = {
        'crawled_at': datetime.now().isoformat(),
        'search_criteria': {
            'enforcement_date_range': f"{start_date}~{end_date}",
            'target': 'eflaw',
            'search_type': 'ì •í™•í•œ_ì‹œí–‰ì¼_ê¸°ì¤€'
        },
        'total_count': len(unique_laws_list),
        'duplicate_removed_count': len(all_laws) - len(unique_laws_list),
        'laws': unique_laws_list
    }
    
    # íŒŒì¼ ì €ì¥
    output_file = 'docs/exact_enforcement_2025_laws.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("=" * 60)
    print(f"âœ… ì •í™•í•œ ì‹œí–‰ì¼ ê¸°ì¤€ 2025ë…„ ë²•ë ¹ í¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë²•ë ¹: {len(all_laws)}ê°œ")
    print(f"ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(unique_laws_list)}ê°œ")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: {output_file}")
    print(f"ğŸ” ê²€ìƒ‰ ê¸°ì¤€: ì‹œí–‰ì¼ {start_date}~{end_date}")
    
    # ìƒ˜í”Œ ì¶œë ¥
    if len(unique_laws_list) > 0:
        print("\nğŸ“‹ ìˆ˜ì§‘ëœ ë²•ë ¹ ìƒ˜í”Œ:")
        for i, law in enumerate(unique_laws_list[:10]):
            print(f"  {i+1}. {law['title']} (ì‹œí–‰: {law['enforcement_date']})")
    
    return result

if __name__ == "__main__":
    crawl_exact_2025_enforcement_laws()