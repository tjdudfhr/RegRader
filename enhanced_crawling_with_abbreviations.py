#!/usr/bin/env python3
import os, sys, json, time, random, re
import urllib.parse, urllib.request
from datetime import datetime
from html import unescape

# ì„¤ì •
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) law-watch/3.3"
OPENAPI_BASE = "https://www.law.go.kr/DRF/lawSearch.do"
LAW_DETAIL_BASE = "https://www.law.go.kr/DRF/lawService.do"
LAW_OC = "20241119YCRNECRQT4Q7SHAZE6P5AXRF"

def http_get(url, timeout=45, headers=None, retries=3, backoff=2.0):
    """HTTP GET ìš”ì²­"""
    last = None
    hdr = {"User-Agent": UA, "Accept": "*/*"}
    if headers: hdr.update(headers)
    
    for i in range(retries):
        try:
            req = urllib.request.Request(url, headers=hdr)
            with urllib.request.urlopen(req, timeout=timeout) as r:
                return r.read()
        except Exception as e:
            last = e
            sleep = (backoff ** i) + random.uniform(0, 0.6)
            print(f"[WARN] GET ì‹¤íŒ¨ ({i+1}/{retries}) {url[:80]}... -> {e}; ì¬ì‹œë„ {sleep:.1f}ì´ˆ í›„", file=sys.stderr)
            time.sleep(sleep)
    
    print(f"[ERROR] GET ìµœì¢… ì‹¤íŒ¨: {url[:80]}... -> {last}", file=sys.stderr)
    return None

def yyyymmdd_to_iso(s):
    """YYYYMMDD í˜•ì‹ì„ YYYY-MM-DDë¡œ ë³€í™˜"""
    if not s: return None
    s = str(s)
    m = re.search(r"(\d{4})(\d{2})(\d{2})", s)
    if not m: return None
    y, mm, dd = map(int, m.groups())
    return f"{y:04d}-{mm:02d}-{dd:02d}"

def extract_law_details(lsId):
    """ë²•ë ¹ ìƒì„¸ ì •ë³´ì—ì„œ ì•½ì¹­ ë“± ì¶”ê°€ ì •ë³´ ì¶”ì¶œ"""
    if not lsId:
        return {}
    
    params = {
        "OC": LAW_OC,
        "target": "law",
        "type": "JSON",
        "lsId": lsId
    }
    
    url = LAW_DETAIL_BASE + "?" + urllib.parse.urlencode(params)
    
    raw = http_get(url)
    if not raw:
        return {}
    
    try:
        data = json.loads(raw.decode("utf-8", "ignore"))
        
        # ë²•ë ¹ ìƒì„¸ ì •ë³´ì—ì„œ ì•½ì¹­, ë³„ì¹­ ë“± ì¶”ì¶œ
        detail_info = {}
        
        if isinstance(data, dict):
            # ë‹¤ì–‘í•œ ê²½ë¡œì—ì„œ ë²•ë ¹ ì •ë³´ ì°¾ê¸°
            law_info = None
            
            if 'LawService' in data:
                law_info = data['LawService']
            elif 'response' in data:
                law_info = data['response']
            elif 'law' in data:
                law_info = data['law']
            
            if law_info and isinstance(law_info, dict):
                # ì•½ì¹­ ê´€ë ¨ í•„ë“œë“¤
                abbreviation_fields = [
                    'ì•½ì¹­', 'ë²•ë ¹ì•½ì¹­', 'abbr', 'abbreviation', 
                    'ë³„ì¹­', 'alias', 'í†µì¹­', 'common_name'
                ]
                
                for field in abbreviation_fields:
                    if field in law_info and law_info[field]:
                        detail_info['abbreviation'] = law_info[field].strip()
                        break
                
                # ê¸°íƒ€ ìœ ìš©í•œ ì •ë³´
                detail_info['full_title'] = law_info.get('ë²•ë ¹ëª…', '').strip()
                detail_info['english_title'] = law_info.get('ë²•ë ¹ì˜ë¬¸ëª…', '').strip()
                
    except Exception as e:
        print(f"[WARN] ë²•ë ¹ ìƒì„¸ì •ë³´ íŒŒì‹± ì‹¤íŒ¨ (lsId: {lsId}): {e}")
    
    return detail_info

def extract_laws_from_json_enhanced(data):
    """JSON ë°ì´í„°ì—ì„œ ë²•ë ¹ ì •ë³´ë¥¼ í–¥ìƒëœ ë°©ë²•ìœ¼ë¡œ ì¶”ì¶œ (ì•½ì¹­ í¬í•¨)"""
    laws = []
    
    if isinstance(data, dict):
        law_list = None
        
        # ë‹¤ì–‘í•œ ê²½ë¡œ ì‹œë„
        if 'LawSearch' in data:
            law_list = data['LawSearch']
        elif 'response' in data:
            law_list = data['response']
        elif 'result' in data:
            law_list = data['result']
        elif 'laws' in data:
            law_list = data['laws']
        elif isinstance(data, list):
            law_list = data
        
        if not law_list:
            return laws
        
        # ë²•ë ¹ ëª©ë¡ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° í•˜ìœ„ í•­ëª© ì°¾ê¸°
        if isinstance(law_list, dict):
            for key, value in law_list.items():
                if isinstance(value, list) and len(value) > 0:
                    law_list = value
                    break
        
        if not isinstance(law_list, list):
            return laws
        
        print(f"ğŸ“‹ {len(law_list)}ê°œ ë²•ë ¹ í•­ëª© ë°œê²¬")
        
        for item in law_list:
            if not isinstance(item, dict):
                continue
            
            # ì‹œí–‰ì¼ í™•ì¸ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª…)
            enforcement_date = None
            for date_field in ['ì‹œí–‰ì¼ì', 'ì‹œí–‰ì¼', 'efYd', 'enfcDate', 'effectiveDate']:
                if date_field in item and item[date_field]:
                    date_str = str(item[date_field])
                    if '2025' in date_str:
                        enforcement_date = yyyymmdd_to_iso(date_str) or date_str
                        break
            
            # 2025ë…„ ì‹œí–‰ì´ ì•„ë‹ˆë©´ ì œì™¸
            if not enforcement_date or '2025' not in enforcement_date:
                continue
            
            # ë²•ë ¹ëª… ì¶”ì¶œ
            title = None
            for title_field in ['ë²•ë ¹ëª…', 'ë²•ë ¹ëª…ì¹­', 'lawNm', 'title']:
                if title_field in item and item[title_field]:
                    title = item[title_field].strip()
                    break
            
            if not title:
                continue
            
            # ë²•ë ¹ ID ì¶”ì¶œ
            lsId = item.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸') or item.get('lsId') or ''
            
            # ë²•ë ¹ ìƒì„¸ ì •ë³´ì—ì„œ ì•½ì¹­ ë“± ì¶”ì¶œ (ì„ íƒì ìœ¼ë¡œ, ë„ˆë¬´ ë§ì€ API í˜¸ì¶œ ë°©ì§€)
            detail_info = {}
            if lsId and len(laws) < 50:  # ì²˜ìŒ 50ê°œë§Œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                detail_info = extract_law_details(lsId)
                time.sleep(0.5)  # API ë¶€í•˜ ë°©ì§€
            
            # ì •ê·œí™”ëœ ë²•ë ¹ ì •ë³´
            law_info = {
                'title': title,
                'enforcement_date': enforcement_date,
                'lsId': lsId,
                'promulgation_date': yyyymmdd_to_iso(item.get('ê³µí¬ì¼ì') or item.get('promDate') or ''),
                'ministry': item.get('ì†Œê´€ë¶€ì²˜') or item.get('minstNm') or '',
                'law_type': item.get('ë²•ì¢…êµ¬ë¶„') or item.get('lawType') or '',
                'abbreviation': detail_info.get('abbreviation', ''),
                'full_title': detail_info.get('full_title', title),
                'english_title': detail_info.get('english_title', ''),
                'raw_data': item
            }
            
            laws.append(law_info)
            
        print(f"âœ… {len(laws)}ê°œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ì¶”ì¶œ ì™„ë£Œ")
    
    return laws

def crawl_2025_laws_with_abbreviations():
    """ì•½ì¹­ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ 2025ë…„ ë²•ë ¹ í¬ë¡¤ë§"""
    
    print("ğŸ” ì•½ì¹­ ì •ë³´ í¬í•¨ 2025ë…„ ì‹œí–‰ ë²•ë ¹ í¬ë¡¤ë§ ì‹œì‘!")
    print("=" * 60)
    
    # 2025ë…„ ì „ì²´ ê¸°ê°„
    start_date = "20250101"
    end_date = "20251231"
    
    all_laws = []
    
    # ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    for page in range(1, 15):  # API ë¶€í•˜ë¥¼ ê³ ë ¤í•˜ì—¬ 15í˜ì´ì§€ê¹Œì§€
        print(f"ğŸ“„ í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")
        
        params = {
            "OC": LAW_OC,
            "target": "eflaw",  # ì‹œí–‰ë²•ë ¹
            "type": "JSON",
            "display": "100",   # í˜ì´ì§€ë‹¹ 100ê°œ
            "page": str(page),
            "efYd": f"{start_date}~{end_date}",  # ì‹œí–‰ì¼ì ë²”ìœ„
            "sort": "efdes",    # ì‹œí–‰ì¼ì ë‚´ë¦¼ì°¨ìˆœ
        }
        
        url = OPENAPI_BASE + "?" + urllib.parse.urlencode(params, safe="~:")
        
        raw = http_get(url)
        if not raw:
            print(f"âŒ í˜ì´ì§€ {page} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            break
            
        # ë””ë²„ê·¸ìš© ì €ì¥
        os.makedirs("docs/_debug", exist_ok=True)
        with open(f"docs/_debug/enhanced_crawl_p{page}.json", "wb") as f:
            f.write(raw)
        
        try:
            data = json.loads(raw.decode("utf-8", "ignore"))
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            break
        
        # ë²•ë ¹ ë°ì´í„° ì¶”ì¶œ (ì•½ì¹­ í¬í•¨)
        page_laws = extract_laws_from_json_enhanced(data)
        
        if not page_laws:
            print(f"ğŸ“„ í˜ì´ì§€ {page}ì—ì„œ 2025ë…„ ì‹œí–‰ ë²•ë ¹ ì—†ìŒ, í¬ë¡¤ë§ ì¢…ë£Œ")
            break
            
        all_laws.extend(page_laws)
        print(f"âœ… í˜ì´ì§€ {page}: {len(page_laws)}ê°œ ë²•ë ¹ ìˆ˜ì§‘ (ì´ {len(all_laws)}ê°œ)")
        
        # API ë¶€í•˜ ë°©ì§€
        if page % 3 == 0:
            print("â¸ï¸ API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°...")
            time.sleep(3)
        else:
            time.sleep(1)
    
    if not all_laws:
        print("âŒ ì•½ì¹­ í¬í•¨ 2025ë…„ ë²•ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ì¤‘ë³µ ì œê±° (lsId ê¸°ì¤€)
    unique_laws = {}
    for law in all_laws:
        key = law['lsId'] or law['title']
        if key not in unique_laws:
            unique_laws[key] = law
    
    unique_laws_list = list(unique_laws.values())
    
    # ê²°ê³¼ ì •ë¦¬
    result = {
        'crawled_at': datetime.now().isoformat(),
        'search_criteria': {
            'enforcement_date_range': f"{start_date}~{end_date}",
            'target': 'eflaw',
            'search_type': 'ì•½ì¹­í¬í•¨_ì‹œí–‰ì¼_ê¸°ì¤€'
        },
        'total_count': len(unique_laws_list),
        'duplicate_removed_count': len(all_laws) - len(unique_laws_list),
        'laws': unique_laws_list
    }
    
    # íŒŒì¼ ì €ì¥
    output_file = 'docs/enhanced_2025_laws_with_abbreviations.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("=" * 60)
    print(f"âœ… ì•½ì¹­ í¬í•¨ 2025ë…„ ë²•ë ¹ í¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë²•ë ¹: {len(all_laws)}ê°œ")
    print(f"ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(unique_laws_list)}ê°œ")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: {output_file}")
    
    # ì•½ì¹­ì´ ìˆëŠ” ë²•ë ¹ ìƒ˜í”Œ ì¶œë ¥
    abbreviation_count = sum(1 for law in unique_laws_list if law.get('abbreviation'))
    print(f"ğŸ“ ì•½ì¹­ ì •ë³´ í¬í•¨ ë²•ë ¹: {abbreviation_count}ê°œ")
    
    print("\nğŸ“‹ ì•½ì¹­ í¬í•¨ ë²•ë ¹ ìƒ˜í”Œ:")
    for i, law in enumerate(unique_laws_list[:10]):
        abbr_info = f" (ì•½ì¹­: {law['abbreviation']})" if law.get('abbreviation') else ""
        print(f"  {i+1}. {law['title']}{abbr_info} (ì‹œí–‰: {law['enforcement_date']})")
    
    return result

if __name__ == "__main__":
    crawl_2025_laws_with_abbreviations()