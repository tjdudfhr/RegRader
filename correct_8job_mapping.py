#!/usr/bin/env python3
"""
ì •í™•í•œ 8ê°œ ì§ë¬´ë³„ ë‹¹ì‚¬ ì ìš©ë²•ê·œì™€ 2,702ê°œ ë²•ë ¹ ë§¤í•‘ ë¶„ì„
- ê¹ƒí—ˆë¸Œ ì €ì¥ëœ ì‹¤ì œ 8ì§ë¬´ ë°ì´í„° ì‚¬ìš©
- ìˆ˜ì¹˜ë§Œ í™•ì¸ìš©
"""

import pandas as pd
import json
import glob
import os
import re
from difflib import SequenceMatcher

class Correct8JobMappingAnalyzer:
    """ì •í™•í•œ 8ì§ë¬´ ë§¤í•‘ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.company_laws = None
        self.collected_laws = None
        
    def load_github_company_laws(self):
        """ê¹ƒí—ˆë¸Œ ì €ì¥ëœ ì‹¤ì œ 8ì§ë¬´ ë‹¹ì‚¬ ì ìš©ë²•ê·œ ë¡œë“œ"""
        
        print("ğŸ“‹ ê¹ƒí—ˆë¸Œ ì €ì¥ëœ 8ì§ë¬´ ë‹¹ì‚¬ ì ìš©ë²•ê·œ ë¡œë“œ ì¤‘...")
        
        try:
            # docs/index.jsonì—ì„œ ì‹¤ì œ ë‹¹ì‚¬ ì ìš©ë²•ê·œ ë¡œë“œ
            with open("/home/user/webapp/docs/index.json", "r", encoding="utf-8") as f:
                data = json.load(f)
            
            laws = []
            for item in data["items"]:
                law_info = {
                    "ë²•ê·œID": item["id"],
                    "ë²•ë ¹ëª…": item["title"], 
                    "ì§ë¬´ì¹´í…Œê³ ë¦¬": item["categories"][0] if item["categories"] else "ë¯¸ë¶„ë¥˜",
                    "ì‹œí–‰ì¼ì": item["effectiveDate"],
                    "ë²•ë ¹ì¢…ë¥˜": item["lawType"],
                    "ì†Œê´€ë¶€ì²˜": item["meta"]["ministry"],
                    "ìš°ì„ ìˆœìœ„": "ë†’ìŒ",  # ëª¨ë“  ë‹¹ì‚¬ ì ìš©ë²•ê·œëŠ” ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •
                    "ì ìš©ë²”ìœ„": "ì „ì‚¬"
                }
                laws.append(law_info)
            
            self.company_laws = pd.DataFrame(laws)
            
            print(f"   âœ… {len(self.company_laws)}ê°œ ë‹¹ì‚¬ ì ìš©ë²•ê·œ ë¡œë“œ ì™„ë£Œ")
            print(f"   ğŸ“‚ ë°ì´í„° ì¶œì²˜: docs/index.json (ê¹ƒí—ˆë¸Œ ì €ì¥)")
            
            # ì§ë¬´ë³„ ë¶„í¬ í™•ì¸
            print(f"   ğŸ“‹ ì§ë¬´ë³„ ë¶„í¬:")
            category_counts = self.company_laws["ì§ë¬´ì¹´í…Œê³ ë¦¬"].value_counts()
            for category, count in category_counts.items():
                print(f"      - {category}: {count}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def load_collected_laws(self):
        """2,702ê°œ ìˆ˜ì§‘ ë²•ë ¹ ë¡œë“œ"""
        
        print("\nğŸ“Š ìˆ˜ì§‘ëœ 2025ë…„ ë²•ë ¹ ë¡œë“œ ì¤‘...")
        
        collected_files = glob.glob("/home/user/webapp/2025_Laws_Complete_*.xlsx")
        if not collected_files:
            collected_files = glob.glob("/home/user/webapp/ë²•ë ¹_2025_í˜„í–‰ì‹œí–‰ì˜ˆì •_*.xlsx")
        
        if not collected_files:
            print("âŒ ìˆ˜ì§‘ëœ ë²•ë ¹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        latest_collected_file = max(collected_files, key=os.path.getctime)
        print(f"   ğŸ“‚ ìˆ˜ì§‘ë²•ë ¹ íŒŒì¼: {os.path.basename(latest_collected_file)}")
        
        try:
            self.collected_laws = pd.read_excel(latest_collected_file, sheet_name="ì „ì²´")
            print(f"   âœ… {len(self.collected_laws)}ê°œ ìˆ˜ì§‘ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"   âŒ ìˆ˜ì§‘ë²•ë ¹ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def normalize_law_name(self, law_name):
        """ë²•ë ¹ëª… ì •ê·œí™”"""
        
        if pd.isna(law_name) or not law_name:
            return ""
        
        name = str(law_name).strip()
        name = re.sub(r'\s+', ' ', name)  # ë‹¤ì¤‘ ê³µë°± ì œê±°
        name = re.sub(r'[^\w\sã„±-ã…ã…-ã…£ê°€-í£]', '', name)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        name = name.replace(' ', '')  # ëª¨ë“  ê³µë°± ì œê±°
        
        return name.lower()
    
    def calculate_similarity(self, name1, name2):
        """ë²•ë ¹ëª… ìœ ì‚¬ë„ ê³„ì‚°"""
        
        norm1 = self.normalize_law_name(name1)
        norm2 = self.normalize_law_name(name2)
        
        if not norm1 or not norm2:
            return 0.0
        
        # ì™„ì „ ì¼ì¹˜
        if norm1 == norm2:
            return 1.0
        
        # í¬í•¨ ê´€ê³„
        if norm1 in norm2 or norm2 in norm1:
            return 0.9
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        return SequenceMatcher(None, norm1, norm2).ratio()
    
    def quick_mapping_analysis(self, min_similarity=0.8):
        """ë¹ ë¥¸ ë§¤í•‘ ë¶„ì„ (ìˆ˜ì¹˜ë§Œ)"""
        
        print(f"\nğŸ” ì •í™•í•œ 8ì§ë¬´ ë§¤í•‘ ë¶„ì„ ì‹¤í–‰ (ìµœì†Œ ìœ ì‚¬ë„: {min_similarity})")
        print("=" * 70)
        
        total_matches = 0
        job_matches = {}
        priority_matches = {}
        status_matches = {}
        future_matches = []
        high_impact_matches = []
        
        # ì§ë¬´ë³„ ì¹´ìš´í„° ì´ˆê¸°í™”
        for job in self.company_laws["ì§ë¬´ì¹´í…Œê³ ë¦¬"].unique():
            job_matches[job] = 0
        
        print(f"ğŸ“‹ ë§¤í•‘ ì§„í–‰ ìƒí™©:")
        
        for idx, company_law in self.company_laws.iterrows():
            company_name = company_law["ë²•ë ¹ëª…"]
            company_job = company_law["ì§ë¬´ì¹´í…Œê³ ë¦¬"]
            company_priority = company_law["ìš°ì„ ìˆœìœ„"]
            
            if (idx + 1) % 50 == 0:
                print(f"   ì§„í–‰ë¥ : {idx+1}/{len(self.company_laws)} ({(idx+1)/len(self.company_laws)*100:.1f}%)")
            
            law_matches = 0
            
            for _, collected_law in self.collected_laws.iterrows():
                collected_name = collected_law["ë²•ë ¹ëª…"]
                similarity = self.calculate_similarity(company_name, collected_name)
                
                if similarity >= min_similarity:
                    law_matches += 1
                    total_matches += 1
                    
                    # ì§ë¬´ë³„ ì¹´ìš´íŠ¸
                    job_matches[company_job] += 1
                    
                    # ìƒíƒœë³„ ì¹´ìš´íŠ¸
                    status = collected_law.get("ë²•ë ¹ìƒíƒœ", "")
                    if status in status_matches:
                        status_matches[status] += 1
                    else:
                        status_matches[status] = 1
                    
                    # ì‹œí–‰ì˜ˆì • ë²•ë ¹ ì²´í¬
                    if status == "ì‹œí–‰ì˜ˆì •":
                        future_matches.append({
                            "ë‹¹ì‚¬ë²•ë ¹": company_name,
                            "ì§ë¬´": company_job,
                            "ìš°ì„ ìˆœìœ„": company_priority,
                            "ì‹œí–‰ì¼ì": collected_law.get("ì‹œí–‰ì¼ì", ""),
                            "ìˆ˜ì§‘ë²•ë ¹": collected_name,
                            "ìœ ì‚¬ë„": similarity
                        })
                        
                        # ëª¨ë“  ë‹¹ì‚¬ ì ìš©ë²•ê·œê°€ ë†’ì€ ìš°ì„ ìˆœìœ„ì´ë¯€ë¡œ 
                        # ì‹œí–‰ì˜ˆì • = ìµœê³  ì˜í–¥ë„
                        high_impact_matches.append({
                            "ë‹¹ì‚¬ë²•ë ¹": company_name,
                            "ì§ë¬´": company_job,
                            "ì‹œí–‰ì¼ì": collected_law.get("ì‹œí–‰ì¼ì", ""),
                            "ìˆ˜ì§‘ë²•ë ¹": collected_name,
                            "ìœ ì‚¬ë„": similarity
                        })
        
        print(f"   ì§„í–‰ë¥ : {len(self.company_laws)}/{len(self.company_laws)} (100.0%)")
        
        return {
            "ì´ë§¤ì¹­ìˆ˜": total_matches,
            "ì§ë¬´ë³„ë§¤ì¹­": job_matches,
            "ìƒíƒœë³„ë§¤ì¹­": status_matches,
            "ì‹œí–‰ì˜ˆì •ë§¤ì¹­": future_matches,
            "ìµœê³ ì˜í–¥ë„ë§¤ì¹­": high_impact_matches
        }
    
    def print_analysis_results(self, results):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        
        print(f"\nğŸ¯ ì •í™•í•œ 8ì§ë¬´ ë²•ë ¹ ë§¤í•‘ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)
        
        # ê¸°ë³¸ í†µê³„
        total_company_laws = len(self.company_laws)
        total_matches = results["ì´ë§¤ì¹­ìˆ˜"]
        match_rate = total_matches / total_company_laws * 100
        
        print(f"ğŸ“Š ê¸°ë³¸ í†µê³„:")
        print(f"   â€¢ ë‹¹ì‚¬ ì ìš©ë²•ê·œ: {total_company_laws:,}ê°œ (ì‹¤ì œ ê¹ƒí—ˆë¸Œ ì €ì¥ ë°ì´í„°)")
        print(f"   â€¢ ìˆ˜ì§‘ëœ ë²•ë ¹: {len(self.collected_laws):,}ê°œ")
        print(f"   â€¢ ì´ ë§¤ì¹­ ìˆ˜: {total_matches:,}ê°œ")
        print(f"   â€¢ ë§¤ì¹­ë¥ : {match_rate:.1f}%")
        
        # ì§ë¬´ë³„ ë§¤ì¹­ í˜„í™©
        print(f"\nğŸ“‹ 8ê°œ ì§ë¬´ë³„ ë§¤ì¹­ í˜„í™©:")
        # ë§¤ì¹­ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_jobs = sorted(results["ì§ë¬´ë³„ë§¤ì¹­"].items(), key=lambda x: x[1], reverse=True)
        for job, count in sorted_jobs:
            job_total = len(self.company_laws[self.company_laws["ì§ë¬´ì¹´í…Œê³ ë¦¬"] == job])
            job_rate = count / job_total * 100 if job_total > 0 else 0
            print(f"   â€¢ {job}: {count:,}ê°œ ë§¤ì¹­ (ë²•ê·œ {job_total}ê°œ ì¤‘ {job_rate:.1f}%)")
        
        # ìƒíƒœë³„ ë§¤ì¹­
        print(f"\nğŸ” ë²•ë ¹ ìƒíƒœë³„ ë§¤ì¹­:")
        for status, count in sorted(results["ìƒíƒœë³„ë§¤ì¹­"].items(), key=lambda x: x[1], reverse=True):
            print(f"   â€¢ {status}: {count:,}ê°œ")
        
        # ì‹œí–‰ì˜ˆì • ë²•ë ¹ (í•µì‹¬!)
        future_count = len(results["ì‹œí–‰ì˜ˆì •ë§¤ì¹­"])
        print(f"\nğŸ”® ì‹œí–‰ì˜ˆì • ë²•ë ¹ ë§¤ì¹­: {future_count:,}ê°œ")
        if future_count > 0:
            print(f"   âš ï¸  2025ë…„ ì¤‘ ë‹¹ì‚¬ì— ì˜í–¥ì„ ì¤„ ìƒˆë¡œìš´ ë²•ë ¹ë“¤")
            
            # ì§ë¬´ë³„ ì‹œí–‰ì˜ˆì • ë¶„í¬
            future_by_job = {}
            for match in results["ì‹œí–‰ì˜ˆì •ë§¤ì¹­"]:
                job = match["ì§ë¬´"]
                if job in future_by_job:
                    future_by_job[job] += 1
                else:
                    future_by_job[job] = 1
            
            print(f"   ğŸ“‹ ì§ë¬´ë³„ ì‹œí–‰ì˜ˆì •:")
            for job, count in sorted(future_by_job.items(), key=lambda x: x[1], reverse=True):
                print(f"      - {job}: {count}ê°œ")
        
        # ìµœê³  ì˜í–¥ë„ (ë‹¹ì‚¬ ì ìš©ë²•ê·œ + ì‹œí–‰ì˜ˆì •)
        high_impact_count = len(results["ìµœê³ ì˜í–¥ë„ë§¤ì¹­"])
        print(f"\nğŸš¨ ìµœê³  ì˜í–¥ë„ ë²•ë ¹: {high_impact_count:,}ê°œ")
        print(f"   (ë‹¹ì‚¬ ì ìš©ë²•ê·œ + ì‹œí–‰ì˜ˆì • = ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”)")
        
        if high_impact_count > 0:
            print(f"   ğŸ”¥ ì¦‰ì‹œ ëŒ€ì‘ í•„ìš” ë²•ë ¹ (ìƒìœ„ 10ê°œ):")
            # ì‹œí–‰ì¼ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_high_impact = sorted(results["ìµœê³ ì˜í–¥ë„ë§¤ì¹­"], 
                                      key=lambda x: x["ì‹œí–‰ì¼ì"])
            
            for i, match in enumerate(sorted_high_impact[:10]):
                print(f"      {i+1:2d}. {match['ì‹œí–‰ì¼ì']}: {match['ë‹¹ì‚¬ë²•ë ¹']} ({match['ì§ë¬´']})")
                if match['ìœ ì‚¬ë„'] < 1.0:
                    print(f"          â†’ ë§¤ì¹­: {match['ìˆ˜ì§‘ë²•ë ¹']} (ìœ ì‚¬ë„: {match['ìœ ì‚¬ë„']:.3f})")
        
        # ë¶„ê¸°ë³„ ì˜í–¥ë„
        if future_count > 0:
            print(f"\nğŸ“… 2025ë…„ ë¶„ê¸°ë³„ ì‹œí–‰ì˜ˆì • ë²•ë ¹:")
            q_counts = {"Q1": 0, "Q2": 0, "Q3": 0, "Q4": 0}
            
            for match in results["ì‹œí–‰ì˜ˆì •ë§¤ì¹­"]:
                date_str = match["ì‹œí–‰ì¼ì"].replace("-", "")
                if "20250101" <= date_str <= "20250331":
                    q_counts["Q1"] += 1
                elif "20250401" <= date_str <= "20250630":
                    q_counts["Q2"] += 1
                elif "20250701" <= date_str <= "20250930":
                    q_counts["Q3"] += 1
                elif "20251001" <= date_str <= "20251231":
                    q_counts["Q4"] += 1
            
            for quarter, count in q_counts.items():
                print(f"   â€¢ 2025 {quarter}: {count}ê°œ")
        
        # ìš”ì•½ ì •ë³´
        print(f"\nğŸ“ˆ í•µì‹¬ ìš”ì•½:")
        print(f"   â€¢ ì „ì²´ ë§¤ì¹­ë¥ : {match_rate:.1f}%")
        print(f"   â€¢ ì‹œí–‰ì˜ˆì • ë²•ë ¹: {future_count}ê°œ (ë‹¹ì‚¬ ëŒ€ì‘ í•„ìš”)")
        print(f"   â€¢ ìµœê³  ìš°ì„ ìˆœìœ„: {high_impact_count}ê°œ (ì¦‰ì‹œ ëŒ€ì‘)")
        if results["ì§ë¬´ë³„ë§¤ì¹­"]:
            max_job = max(results['ì§ë¬´ë³„ë§¤ì¹­'].items(), key=lambda x: x[1])
            print(f"   â€¢ ê°€ì¥ ë§ì€ ë§¤ì¹­ ì§ë¬´: {max_job[0]} ({max_job[1]}ê°œ)")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ ì •í™•í•œ 8ì§ë¬´ vs 2,702ê°œ ë²•ë ¹ ë§¤í•‘ ë¶„ì„")
    print("ğŸ”¹ ê¹ƒí—ˆë¸Œ ì €ì¥ëœ ì‹¤ì œ ë‹¹ì‚¬ ì ìš©ë²•ê·œ ì‚¬ìš©")
    print("=" * 70)
    
    analyzer = Correct8JobMappingAnalyzer()
    
    # ë°ì´í„° ë¡œë“œ
    if not analyzer.load_github_company_laws():
        return
    
    if not analyzer.load_collected_laws():
        return
    
    # ë§¤í•‘ ë¶„ì„
    results = analyzer.quick_mapping_analysis(min_similarity=0.8)
    
    # ê²°ê³¼ ì¶œë ¥
    analyzer.print_analysis_results(results)
    
    print(f"\nâœ… ì •í™•í•œ 8ì§ë¬´ ë§¤í•‘ ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()